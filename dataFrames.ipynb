{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b91ef4f",
   "metadata": {},
   "source": [
    "## Basic Data Frame Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e6b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"Data Frame\").getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2389633d",
   "metadata": {},
   "source": [
    "the entry point to programming spark with the data frame is spark session\n",
    "\n",
    "with a sql context, applications can create data frames from an existing RDD, from a hive table or from data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "905b8216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "\n",
    "# old way of creating spark context\n",
    "sc1=SparkContext(master='local',appName='test1')\n",
    "\n",
    "# creating spark session \n",
    "spark1=SparkSession(sc1)\n",
    "\n",
    "# creating SQL context\n",
    "sqlcontext1=SQLContext(sc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db475e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark=SparkSession.builder.appName(\"test\").getOrCreate()\n",
    "\n",
    "# for rdd learning \n",
    "sc=spark.sparkContext\n",
    "rdd=sc.textFile(\"test.csv\")\n",
    "\n",
    "#  for dataframe purpose\n",
    "df=spark.read.csv('test.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e61de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Sepal_Length: double, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string]\n",
      "DataFrame[Sepal_Length: string, Sepal_Width: string, Petal_Length: string, Petal_Width: string, Species: string]\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|Petal_Length|Petal_Width|Sepal_Length|Sepal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         1.4|        0.2|         5.1|        3.5| setosa|\n",
      "|         1.4|        0.2|         4.9|        3.0| setosa|\n",
      "|         1.3|        0.2|         4.7|        3.2| setosa|\n",
      "|         1.5|        0.2|         4.6|        3.1| setosa|\n",
      "|         1.4|        0.2|         5.0|        3.6| setosa|\n",
      "|         1.7|        0.4|         5.4|        3.9| setosa|\n",
      "|         1.4|        0.3|         4.6|        3.4| setosa|\n",
      "|         1.5|        0.2|         5.0|        3.4| setosa|\n",
      "|         1.4|        0.2|         4.4|        2.9| setosa|\n",
      "|         1.5|        0.1|         4.9|        3.1| setosa|\n",
      "|         1.5|        0.2|         5.4|        3.7| setosa|\n",
      "|         1.6|        0.2|         4.8|        3.4| setosa|\n",
      "|         1.4|        0.1|         4.8|        3.0| setosa|\n",
      "|         1.1|        0.1|         4.3|        3.0| setosa|\n",
      "|         1.2|        0.2|         5.8|        4.0| setosa|\n",
      "|         1.5|        0.4|         5.7|        4.4| setosa|\n",
      "|         1.3|        0.4|         5.4|        3.9| setosa|\n",
      "|         1.4|        0.3|         5.1|        3.5| setosa|\n",
      "|         1.7|        0.3|         5.7|        3.8| setosa|\n",
      "|         1.5|        0.3|         5.1|        3.8| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Importing data using spark session\n",
    "df1 = spark1.read.csv(path=\"iris/iris.csv\", sep=\",\", header=True)\n",
    "# full example\n",
    "df1 = spark.read.csv(\n",
    "    \"iris/iris.csv\",\n",
    "    sep=\",\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    nullValue=\"NA\",\n",
    "    mode=\"PERMISSIVE\",\n",
    "    ignoreLeadingWhiteSpace=True,\n",
    ")\n",
    "\n",
    "# importing data using sql context\n",
    "df2 = sqlcontext1.read.csv(path=\"iris/iris.csv\", sep=\",\", header=True)\n",
    "\n",
    "# sqlcontext is old api, used for sql & dataframes(old style)\n",
    "\n",
    "print(df1)\n",
    "# print(df1.show())\n",
    "print(df2)\n",
    "\n",
    "iris1_df1 = spark1.read.json(\"iris/iris.json\")\n",
    "\n",
    "iris1_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6acd9472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+------+\n",
      "| _1| _2| _3| _4|    _5|\n",
      "+---+---+---+---+------+\n",
      "|5.1|3.5|1.4|0.2|setosa|\n",
      "|4.9|3.0|1.4|0.2|setosa|\n",
      "|4.7|3.2|1.3|0.2|setosa|\n",
      "|4.6|3.1|1.5|0.2|setosa|\n",
      "|5.0|3.6|1.4|0.2|setosa|\n",
      "|5.4|3.9|1.7|0.4|setosa|\n",
      "|4.6|3.4|1.4|0.3|setosa|\n",
      "|5.0|3.4|1.5|0.2|setosa|\n",
      "|4.4|2.9|1.4|0.2|setosa|\n",
      "|4.9|3.1|1.5|0.1|setosa|\n",
      "+---+---+---+---+------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Convert RDD to Data Frame \n",
    "# using createDataFrame function\n",
    "iris1=sc1.textFile('iris/iris_site.csv')\n",
    "iris1_split=iris1.map(lambda line:line.split(\",\"))\n",
    "\n",
    "df1=spark1.createDataFrame(iris1_split)\n",
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98946203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5.1', '3.5', '1.4', '0.2', 'setosa'),\n",
       " ('4.9', '3.0', '1.4', '0.2', 'setosa'),\n",
       " ('4.7', '3.2', '1.3', '0.2', 'setosa'),\n",
       " ('4.6', '3.1', '1.5', '0.2', 'setosa'),\n",
       " ('5.0', '3.6', '1.4', '0.2', 'setosa'),\n",
       " ('5.4', '3.9', '1.7', '0.4', 'setosa'),\n",
       " ('4.6', '3.4', '1.4', '0.3', 'setosa'),\n",
       " ('5.0', '3.4', '1.5', '0.2', 'setosa'),\n",
       " ('4.4', '2.9', '1.4', '0.2', 'setosa'),\n",
       " ('4.9', '3.1', '1.5', '0.1', 'setosa')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dataframe to rdd \n",
    "iris1_df1=spark1.read.csv('iris/iris.csv',sep=',',header=True)\n",
    "iris1_df1.rdd.map(tuple).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df02474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Sepal_Length='5.1', Sepal_Width='3.5', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.9', Sepal_Width='3.0', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.7', Sepal_Width='3.2', Petal_Length='1.3', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.6', Sepal_Width='3.1', Petal_Length='1.5', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='5.0', Sepal_Width='3.6', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='5.4', Sepal_Width='3.9', Petal_Length='1.7', Petal_Width='0.4', Species='setosa'),\n",
       " Row(Sepal_Length='4.6', Sepal_Width='3.4', Petal_Length='1.4', Petal_Width='0.3', Species='setosa'),\n",
       " Row(Sepal_Length='5.0', Sepal_Width='3.4', Petal_Length='1.5', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.4', Sepal_Width='2.9', Petal_Length='1.4', Petal_Width='0.2', Species='setosa'),\n",
       " Row(Sepal_Length='4.9', Sepal_Width='3.1', Petal_Length='1.5', Petal_Width='0.1', Species='setosa')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display contents of data frame in table format\n",
    "iris_df1=spark1.read.csv('iris/iris.csv',sep=',',header=True)\n",
    "iris1_df1.show(5) # shows only top 5 rows\n",
    "\n",
    "iris1_df1.collect() # display content of dataframe as a list of rows\n",
    "\n",
    "iris1_df1.head(10) # shows 1st 1 rows of data frame as a list of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ab6df4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sepal_Length: string (nullable = true)\n",
      " |-- Sepal_Width: string (nullable = true)\n",
      " |-- Petal_Length: string (nullable = true)\n",
      " |-- Petal_Width: string (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display all columns\n",
    "iris_df1.columns\n",
    "\n",
    "iris_df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f23c249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|Sepal_Length|Species|\n",
      "+------------+-------+\n",
      "|         5.1| setosa|\n",
      "|         4.9| setosa|\n",
      "|         4.7| setosa|\n",
      "|         4.6| setosa|\n",
      "|         5.0| setosa|\n",
      "|         5.4| setosa|\n",
      "|         4.6| setosa|\n",
      "|         5.0| setosa|\n",
      "|         4.4| setosa|\n",
      "|         4.9| setosa|\n",
      "|         5.4| setosa|\n",
      "|         4.8| setosa|\n",
      "|         4.8| setosa|\n",
      "|         4.3| setosa|\n",
      "|         5.8| setosa|\n",
      "|         5.7| setosa|\n",
      "|         5.4| setosa|\n",
      "|         5.1| setosa|\n",
      "|         5.7| setosa|\n",
      "|         5.1| setosa|\n",
      "+------------+-------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Data Selection\n",
    "# selecting any particular column\n",
    "iris1_df1=spark1.read.csv('iris/iris.csv',sep=',',header=True)\n",
    "iris1_df1.select(\"Sepal_Length\",\"Species\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efd1bdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|SepalLength|SpeciesType|\n",
      "+-----------+-----------+\n",
      "|        5.1|     setosa|\n",
      "|        4.9|     setosa|\n",
      "|        4.7|     setosa|\n",
      "|        4.6|     setosa|\n",
      "|        5.0|     setosa|\n",
      "|        5.4|     setosa|\n",
      "|        4.6|     setosa|\n",
      "|        5.0|     setosa|\n",
      "+-----------+-----------+\n",
      "only showing top 8 rows\n"
     ]
    }
   ],
   "source": [
    "# renaming columns while selecting\n",
    "from pyspark.sql.functions import col\n",
    "iris_df1.select(col(\"Sepal_Length\").alias(\"SepalLength\"),\n",
    "                col(\"Species\").alias(\"SpeciesType\")).show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c0aeca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 8 rows\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# filter rows\n",
    "iris_df1.filter(col(\"Sepal_Length\")>4.5).show(8)\n",
    "\n",
    "# multiple conditions \n",
    "iris_df1.filter((col(\"Sepal_Length\")>4.5) & (col(\"Species\")==\"setosa\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a71ca877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|Sepal_Length|Species|\n",
      "+------------+-------+\n",
      "|         5.1| setosa|\n",
      "|         4.9| setosa|\n",
      "|         5.0| setosa|\n",
      "|         5.4| setosa|\n",
      "|         5.0| setosa|\n",
      "|         4.9| setosa|\n",
      "|         5.4| setosa|\n",
      "|         4.8| setosa|\n",
      "+------------+-------+\n",
      "only showing top 8 rows\n"
     ]
    }
   ],
   "source": [
    "# select + filter together \n",
    "iris1_df1.select(\"Sepal_Length\",\"Species\").filter(col(\"Sepal_Length\")>4.7).show(8) # order doesnt matter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18973551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+---------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|NewColumn|\n",
      "+------------+-----------+------------+-----------+-------+---------+\n",
      "|        10.1|        3.5|         1.4|        0.2| setosa|     test|\n",
      "|         9.9|        3.0|         1.4|        0.2| setosa|     test|\n",
      "|         9.7|        3.2|         1.3|        0.2| setosa|     test|\n",
      "|         9.6|        3.1|         1.5|        0.2| setosa|     test|\n",
      "|        10.0|        3.6|         1.4|        0.2| setosa|     test|\n",
      "|        10.4|        3.9|         1.7|        0.4| setosa|     test|\n",
      "|         9.6|        3.4|         1.4|        0.3| setosa|     test|\n",
      "|        10.0|        3.4|         1.5|        0.2| setosa|     test|\n",
      "|         9.4|        2.9|         1.4|        0.2| setosa|     test|\n",
      "|         9.9|        3.1|         1.5|        0.1| setosa|     test|\n",
      "+------------+-----------+------------+-----------+-------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# withColumn(add/modify columns)\n",
    "# add new column \n",
    "# lit() --> used to set constant value\n",
    "\n",
    "from pyspark.sql.functions import col,lit \n",
    "df2=iris1_df1.withColumn(\"NewColumn\",lit(\"test\"))\n",
    "# df2.show()\n",
    "\n",
    "# to modify a value\n",
    "# df2.withColumn(\"Sepal_Length\",col(\"Sepal_Length\")+5).show() # this is string type so we need to convert to float\n",
    "# dataframe is immutable,so we need to reassign\n",
    "df2=df2.withColumn(\"Sepal_Length\",col(\"Sepal_Length\").cast(\"double\")+5.0)\n",
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7069992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+----------+---------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|   Species|NewColumn|\n",
      "+------------+-----------+------------+-----------+----------+---------+\n",
      "|         5.1|        3.5|         1.4|        0.2|newSpecies|     test|\n",
      "|         4.9|        3.0|         1.4|        0.2|newSpecies|     test|\n",
      "|         4.7|        3.2|         1.3|        0.2|newSpecies|     test|\n",
      "|         4.6|        3.1|         1.5|        0.2|newSpecies|     test|\n",
      "|         5.0|        3.6|         1.4|        0.2|newSpecies|     test|\n",
      "+------------+-----------+------------+-----------+----------+---------+\n",
      "only showing top 5 rows\n",
      "+------------+-----------+------------+-----------+----------+---------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|newSpecies|NewColumn|\n",
      "+------------+-----------+------------+-----------+----------+---------+\n",
      "|         5.1|        3.5|         1.4|        0.2|    setosa|     test|\n",
      "|         4.9|        3.0|         1.4|        0.2|    setosa|     test|\n",
      "|         4.7|        3.2|         1.3|        0.2|    setosa|     test|\n",
      "|         4.6|        3.1|         1.5|        0.2|    setosa|     test|\n",
      "|         5.0|        3.6|         1.4|        0.2|    setosa|     test|\n",
      "|         5.4|        3.9|         1.7|        0.4|    setosa|     test|\n",
      "|         4.6|        3.4|         1.4|        0.3|    setosa|     test|\n",
      "|         5.0|        3.4|         1.5|        0.2|    setosa|     test|\n",
      "|         4.4|        2.9|         1.4|        0.2|    setosa|     test|\n",
      "|         4.9|        3.1|         1.5|        0.1|    setosa|     test|\n",
      "|         5.4|        3.7|         1.5|        0.2|    setosa|     test|\n",
      "|         4.8|        3.4|         1.6|        0.2|    setosa|     test|\n",
      "|         4.8|        3.0|         1.4|        0.1|    setosa|     test|\n",
      "|         4.3|        3.0|         1.1|        0.1|    setosa|     test|\n",
      "|         5.8|        4.0|         1.2|        0.2|    setosa|     test|\n",
      "|         5.7|        4.4|         1.5|        0.4|    setosa|     test|\n",
      "|         5.4|        3.9|         1.3|        0.4|    setosa|     test|\n",
      "|         5.1|        3.5|         1.4|        0.3|    setosa|     test|\n",
      "|         5.7|        3.8|         1.7|        0.3|    setosa|     test|\n",
      "|         5.1|        3.8|         1.5|        0.3|    setosa|     test|\n",
      "+------------+-----------+------------+-----------+----------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# modify existing column \n",
    "df2.withColumn(\"Species\",lit(\"newSpecies\")).show(5) # Species column is modified to new species\n",
    "# to just rename the column use\n",
    "df2=df2.withColumnRenamed(\"Species\",\"newSpecies\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ab404",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "\n",
    "sorting in spark --> distributed sort+shuffle\n",
    "\n",
    "it reorders entire rows, not just columns\n",
    "\n",
    "sort is just an alias for orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efe70f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.4|        3.0|         1.3|        0.2| setosa|\n",
      "|         4.4|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.5|        2.3|         1.3|        0.3| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         4.6|        3.6|         1.0|        0.2| setosa|\n",
      "|         4.6|        3.2|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|  Species|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "|         7.9|        3.8|         6.4|        2.0|virginica|\n",
      "|         7.7|        2.6|         6.9|        2.3|virginica|\n",
      "|         7.7|        3.0|         6.1|        2.3|virginica|\n",
      "|         7.7|        2.8|         6.7|        2.0|virginica|\n",
      "|         7.7|        3.8|         6.7|        2.2|virginica|\n",
      "|         7.6|        3.0|         6.6|        2.1|virginica|\n",
      "|         7.4|        2.8|         6.1|        1.9|virginica|\n",
      "|         7.3|        2.9|         6.3|        1.8|virginica|\n",
      "|         7.2|        3.6|         6.1|        2.5|virginica|\n",
      "|         7.2|        3.2|         6.0|        1.8|virginica|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "only showing top 10 rows\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|  Species|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "|         7.9|        3.8|         6.4|        2.0|virginica|\n",
      "|         7.7|        2.6|         6.9|        2.3|virginica|\n",
      "|         7.7|        3.0|         6.1|        2.3|virginica|\n",
      "|         7.7|        2.8|         6.7|        2.0|virginica|\n",
      "|         7.7|        3.8|         6.7|        2.2|virginica|\n",
      "|         7.6|        3.0|         6.6|        2.1|virginica|\n",
      "|         7.4|        2.8|         6.1|        1.9|virginica|\n",
      "|         7.3|        2.9|         6.3|        1.8|virginica|\n",
      "|         7.2|        3.6|         6.1|        2.5|virginica|\n",
      "|         7.2|        3.2|         6.0|        1.8|virginica|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Sorting(orderBy)\n",
    "iris1_df1.orderBy(\"Sepal_Length\").show(10) # ascending\n",
    "\n",
    "# iris1_df1.orderBy(\"Sepal_Length\".desc()).show() # it gives error bcz str should be converted \n",
    "iris1_df1.orderBy(col(\"Sepal_Length\").desc()).show(10)\n",
    "# this can be written\n",
    "iris_df1.orderBy(\"Sepal_Length\",ascending=False).show(10)\n",
    "\n",
    "# iris_df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2befaa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.4|        3.0|         1.3|        0.2| setosa|\n",
      "|         4.4|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.5|        2.3|         1.3|        0.3| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         4.6|        3.6|         1.0|        0.2| setosa|\n",
      "|         4.6|        3.2|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# sorting by multiple columns \n",
    "# sort by species then by Sepal_Length\n",
    "iris_df1.orderBy(\"Species\",\"Sepal_Length\").show(10) \n",
    "# groups rows by species, and within each species sorts by Sepal_Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c620c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Sepal_Length: string, Sepal_Width: string, Petal_Length: string, Petal_Width: string, Species: string]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting+null values \n",
    "# default behaviour --> nulls comes first in ascending, nulls come last in descending\n",
    "# control it manually\n",
    "iris_df1.orderBy(col(\"Sepal_Length\").asc_nulls_last())\n",
    "iris_df1.orderBy(col(\"Sepal_Length\").asc_nulls_first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ea79a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.5|        4.2|         1.4|        0.2| setosa|\n",
      "|         5.5|        3.5|         1.3|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.4|        3.4|         1.7|        0.2| setosa|\n",
      "|         5.4|        3.4|         1.5|        0.4| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# mixed order directions \n",
    "iris_df1.orderBy(\n",
    "    col(\"Species\").asc(),\n",
    "    col(\"Sepal_Length\").desc()\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ab46ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+---------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|  Species|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "|         7.9|        3.8|         6.4|        2.0|virginica|\n",
      "|         7.7|        3.8|         6.7|        2.2|virginica|\n",
      "|         7.7|        2.6|         6.9|        2.3|virginica|\n",
      "|         7.7|        2.8|         6.7|        2.0|virginica|\n",
      "|         7.7|        3.0|         6.1|        2.3|virginica|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sorting +limit \n",
    "iris1_df1.orderBy(col(\"Sepal_Length\").desc()).limit(5).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9ff9c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['Sepal_Length ASC NULLS FIRST], true\n",
      "+- Relation [Sepal_Length#137,Sepal_Width#138,Petal_Length#139,Petal_Width#140,Species#141] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Sepal_Length: string, Sepal_Width: string, Petal_Length: string, Petal_Width: string, Species: string\n",
      "Sort [Sepal_Length#137 ASC NULLS FIRST], true\n",
      "+- Relation [Sepal_Length#137,Sepal_Width#138,Petal_Length#139,Petal_Width#140,Species#141] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [Sepal_Length#137 ASC NULLS FIRST], true\n",
      "+- Relation [Sepal_Length#137,Sepal_Width#138,Petal_Length#139,Petal_Width#140,Species#141] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [Sepal_Length#137 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(Sepal_Length#137 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=538]\n",
      "      +- FileScan csv [Sepal_Length#137,Sepal_Width#138,Petal_Length#139,Petal_Width#140,Species#141] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/c:/Users/emada/Downloads/DSE Stream Training/Pyspark/iris/iris.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Sepal_Length:string,Sepal_Width:string,Petal_Length:string,Petal_Width:string,Species:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris1_df1.orderBy(\"Sepal_Length\").explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e049f0c5",
   "metadata": {},
   "source": [
    "### Handling Null Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2435b71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# count nulls in a column \n",
    "from pyspark.sql.functions import col \n",
    "iris1_df1.filter(col(\"Sepal_Length\").isNull()).show()\n",
    "\n",
    "# not null\n",
    "iris1_df1.filter(col(\"Sepal_Length\").isNotNull()).show(10)\n",
    "\n",
    "# drop rows with nulls\n",
    "\n",
    "# drop rows having any null\n",
    "iris_df1.na.drop()\n",
    "\n",
    "# drop rows only if all columns are null\n",
    "iris1_df1.na.drop(how=\"all\")\n",
    "\n",
    "# drop rows if null in specific columns \n",
    "iris_df1=iris1_df1.na.drop(subset=[\"Sepal_Length\",\"Species\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b219a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# fill null values \n",
    "\n",
    "# fill all numeric nulls with 0 \n",
    "iris1_df1.na.fill(0)\n",
    "\n",
    "# fill specific columns \n",
    "iris1_df1.na.fill({\"Sepal_Length\":0.0,\"Species\":\"unknown\"}).show(5) # replaces nulls with these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "755c0145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| SETOSA|\n",
      "|         4.9|        3.0|         1.4|        0.2| SETOSA|\n",
      "|         4.7|        3.2|         1.3|        0.2| SETOSA|\n",
      "|         4.6|        3.1|         1.5|        0.2| SETOSA|\n",
      "|         5.0|        3.6|         1.4|        0.2| SETOSA|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| SETOSA|\n",
      "|         4.9|        3.0|         1.4|        0.2| SETOSA|\n",
      "|         4.7|        3.2|         1.3|        0.2| SETOSA|\n",
      "|         4.6|        3.1|         1.5|        0.2| SETOSA|\n",
      "|         5.0|        3.6|         1.4|        0.2| SETOSA|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# replace values(Not only nulls)\n",
    "iris1_df1.na.replace(\"setosa\",\"SETOSA\").show(5)\n",
    "\n",
    "# multiple\n",
    "# replace in Species\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "iris1_df1 = iris1_df1.withColumn(\n",
    "    \"Species\", when(col(\"Species\") == \"setosa\", \"SETOSA\").otherwise(col(\"Species\"))\n",
    ")\n",
    "\n",
    "iris1_df1 = iris1_df1.withColumn(\n",
    "    \"Sepal_Length\",\n",
    "    when(col(\"Sepal_Length\") == \"1.3\", \"10.0\").otherwise(col(\"Sepal_Length\")),\n",
    ")\n",
    "\n",
    "iris1_df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a8e925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls vs empty strings\n",
    "# df.filter(col(\"Species\")==\"\")\n",
    "from pyspark.sql.functions import when \n",
    "iris_df1=iris_df1.withColumn(\n",
    "    \"Species\",\n",
    "    when(col(\"Species\")==\"\",None).otherwise(col(\"Species\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46409d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+---+---+------------+-----------+-------+\n",
      "|Sepal_Length|Sepal_Width| ID| ID|Petal_Length|Petal_Width|Species|\n",
      "+------------+-----------+---+---+------------+-----------+-------+\n",
      "|         5.1|        3.5|  1|  1|         1.4|        0.2| setosa|\n",
      "|         4.9|          3|  2|  2|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|  3|  3|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|  4|  4|         1.5|        0.2| setosa|\n",
      "|           5|        3.6|  5|  5|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|  6|  6|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|  7|  7|         1.4|        0.3| setosa|\n",
      "|           5|        3.4|  8|  8|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|  9|  9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1| 10| 10|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7| 11| 11|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4| 12| 12|         1.6|        0.2| setosa|\n",
      "|         4.8|          3| 13| 13|         1.4|        0.1| setosa|\n",
      "|         4.3|          3| 14| 14|         1.1|        0.1| setosa|\n",
      "|         5.8|          4| 15| 15|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4| 16| 16|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9| 17| 17|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5| 18| 18|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8| 19| 19|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8| 20| 20|         1.5|        0.3| setosa|\n",
      "+------------+-----------+---+---+------------+-----------+-------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# joining two tables where the joining columns present in the two\n",
    "# tables have a different name \n",
    "iris1_df1.join(other=iris1_df2,on=(iris1_df1.ID==iris1_df2.ID),how='inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8000fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('CustomerId', IntegerType(), True), StructField('CustomerName', StringType(), True), StructField('CustomerLocation', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "# StructType (used to define the schema of the row)\n",
    "import pyspark\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "empSchema = pyspark.sql.types.StructType(\n",
    "    [\n",
    "        StructField(\"CustomerId\", IntegerType(), True),\n",
    "        StructField(\"CustomerName\", StringType(), True),\n",
    "        StructField(\"CustomerLocation\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(empSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3d0a5eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|CustomerId|CustomerName|    CustomerLocation|\n",
      "+----------+------------+--------------------+\n",
      "|      1002|        Aman|     1 Anthes Avenue|\n",
      "|      1003|       Harsh|   87985 Linden Pass|\n",
      "|      1004|       Ayush| 56 La Follette Pass|\n",
      "|      1005|       Aditi|  8 Briar Crest Pass|\n",
      "|      1006|      Anjali|    035 Iowa Terrace|\n",
      "|      1007|     Shubham|    3925 Clove Drive|\n",
      "|      1008|     Anushka|    9 Straubel Drive|\n",
      "|      1009|       Rohit|   816 Northland Way|\n",
      "|      1010|     Saurabh|    10165 Gerald Way|\n",
      "|      1011|      Muskan|83 Merchant Junction|\n",
      "|      1012|       Rahul|1249 Summerview Pass|\n",
      "|      1013|     Utkarsh|   5 Bowman Junction|\n",
      "|      1014|     Vaibhav|      3 Chinook Park|\n",
      "|      1015|        Amit|   90535 Bonner Lane|\n",
      "|      1016|      Saumya| 056 Straubel Avenue|\n",
      "|      1017|     Rishabh| 70 Wayridge Parkway|\n",
      "|      1018|      Shruti|     609 Truax Alley|\n",
      "|      1019|    Himanshu|948 Marquette Circle|\n",
      "|      1020|       Kajal|  4121 Atwood Circle|\n",
      "|      1021|       Ankit|    31 Center Avenue|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('CustomerId', 'int'),\n",
       " ('CustomerName', 'string'),\n",
       " ('CustomerLocation', 'string')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning defined structure to dataframe\n",
    "import pyspark\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "empSchema = pyspark.sql.types.StructType(\n",
    "    [\n",
    "        StructField(\"CustomerId\", IntegerType(), True),\n",
    "        StructField(\"CustomerName\", StringType(), True),\n",
    "        StructField(\"CustomerLocation\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .schema(empSchema)\n",
    "    .option(\"header\", True)\n",
    "    .load(\"Cust_address.csv\")\n",
    ")\n",
    "df.show()\n",
    "df.dtypes\n",
    "\n",
    "# df.drop(\"CustomerLocation\") # drop column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
