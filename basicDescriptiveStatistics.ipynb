{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc15bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"Descriptive Statistics\").getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3714a05",
   "metadata": {},
   "source": [
    "Basic Descriptive Statistics on RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3825512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('b', 4)]\n",
      "[('a', 2)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x22c6438a9d0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x22c645caad0>)),\n",
       " ('b',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x22c50e6a910>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x22c645c86d0>))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine multiple rdd data with same key\n",
    "# we use 'cogroup' function\n",
    "p1=sc.parallelize([\n",
    "    (\"a\",1),(\"b\",4)\n",
    "])\n",
    "p2=sc.parallelize([\n",
    "    (\"a\",2)\n",
    "])\n",
    "print(p1.collect())\n",
    "print(p2.collect())\n",
    "\n",
    "p1.cogroup(p2).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ee43eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', ([1], [2])), ('b', ([4], []))]\n"
     ]
    }
   ],
   "source": [
    "# the result of cogroup function can be realized by combining\n",
    "# for loop with tuple & map\n",
    "p1 = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
    "p2 = sc.parallelize([(\"a\", 2)])\n",
    "\n",
    "result = [(x, tuple(map(list, y))) for x, y in p1.cogroup(p2).collect()]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90d9418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-setosa ([6], [4], [], [7])\n",
      "setosa ([5], [1], [2], [])\n"
     ]
    }
   ],
   "source": [
    "# combining multiple rdd (more than 2rdd's)\n",
    "# we can use groupWith Function\n",
    "data1=sc.parallelize([\n",
    "    (\"setosa\",5),(\"non-setosa\",6)\n",
    "])\n",
    "data2 = sc.parallelize([(\"setosa\", 1), (\"non-setosa\", 4)])\n",
    "data3 = sc.parallelize([(\"setosa\", 2)])\n",
    "data4 = sc.parallelize([(\"non-setosa\", 7)])\n",
    "groupwith1 = data1.groupWith(data2, data3, data4).collect()\n",
    "\n",
    "for x,y in groupwith1:\n",
    "    print(x,tuple(map(list,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31884d",
   "metadata": {},
   "source": [
    "Count Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b894e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('setosa', 2), ('non-setosa', 1)])\n"
     ]
    }
   ],
   "source": [
    "p1=sc.parallelize([\n",
    "    (\"setosa\",1),(\"non-setosa\",1),(\"setosa\",1)\n",
    "])\n",
    "print(p1.countByKey().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b358cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('setosa', 50), ('versicolor', 50), ('virginica', 50)])\n"
     ]
    }
   ],
   "source": [
    "iris1 = sc.textFile(\"iris/iris_site.csv\")\n",
    "iris1_split = iris1.map(lambda var1: var1.split(\",\"))\n",
    "iris1_mod = iris1_split.map(lambda var1: (var1[4], 1))\n",
    "print(iris1_mod.countByKey().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c31a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('setosa', 50), ('versicolor', 50), ('virginica', 50)])\n"
     ]
    }
   ],
   "source": [
    "# count total occurences of values in a particular column can be calculated \n",
    "# by countByValue function\n",
    "\n",
    "print(iris1_split.map(lambda col:col[4]).countByValue().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfde6bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "# count total number of values\n",
    "print(iris1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2220a960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Distinct\n",
    "\n",
    "iris1_mod=iris1_split.map(lambda col:col[4])\n",
    "distinct1=iris1_mod.distinct()\n",
    "print(distinct1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2ad8c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# generate sequence of values\n",
    "range1=sc.range(start=1,end=10,step=2)\n",
    "print(range1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f0eb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sepal_Length', 15), ('Sepal_Width', 12)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function for each key\n",
    "# to apply some function to the values of a particular key we should use mapValues function\n",
    "data1 = sc.parallelize(\n",
    "    [(\"Sepal_Length\", [2, 1, 3, 5, 4]), (\"Sepal_Width\", [3, 1, 2, 4, 2])]\n",
    ")\n",
    "\n",
    "def func(para1):\n",
    "    return sum(para1)\n",
    "\n",
    "data1.mapValues(func).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4653b01d",
   "metadata": {},
   "source": [
    "## Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000dedb",
   "metadata": {},
   "source": [
    "fold is an action that aggregates (combines) all elements of an RDD into ONE value.\n",
    "\n",
    "rdd.fold(zeroValue,func)\n",
    "\n",
    "start with an initial value then combine all elements using the same function\n",
    "\n",
    "foldByKey() --> works on pair RDD's\n",
    "\n",
    "(key,value)\n",
    "\n",
    "rdd.foldByKey(zeroValue, func) --> For each key, start with zeroValue and combine all its values using the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ea752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458.6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure data in  an RDD can be aggregated using fold function\n",
    "\n",
    "\n",
    "from operator import add\n",
    "\n",
    "iris1 = sc.textFile(\"iris/iris_site.csv\")\n",
    "iris1_split = iris1.map(lambda var1: var1.split(\",\"))\n",
    "iris1_mod = iris1_split.map(lambda col: col[1])\n",
    "iris1_split.map(lambda col: float(col[1])).fold(0, add)\n",
    "\n",
    "round(iris1_split.map(lambda col: float(col[1])).fold(0, add), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6866276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 3), ('b', 3)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"a\", 2), (\"b\", 3)])\n",
    "rdd.foldByKey(0,add).collect()\n",
    "\n",
    "# here 1st for the key 'a' ---> 0+1+2\n",
    "# for the key 'b' --> 0+3\n",
    "# o/p: a-3,b-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1cf93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sepal.Width', 458.6000000000001), ('Petal.Width', 179.89999999999998), ('Sepal.Length', 876.4999999999998), ('Petal.Length', 563.7000000000002)]\n"
     ]
    }
   ],
   "source": [
    "# Aggregate by key\n",
    "# to aggregate values in each column we use foldByKey\n",
    "# fold is an action that aggregates (combines) all elements of an RDD into ONE value.\n",
    "from operator import add\n",
    "\n",
    "iris1 = sc.textFile(\"iris/iris_site.csv\")\n",
    "iris1_split = iris1.map(lambda var1: var1.split(\",\"))\n",
    "iris1_mod = iris1_split.flatMap(\n",
    "    lambda var1: (\n",
    "        (\"Sepal.Length\", float(var1[0])),\n",
    "        (\"Sepal.Width\", float(var1[1])),\n",
    "        (\"Petal.Length\", float(var1[2])),\n",
    "        (\"Petal.Width\", float(var1[3])),\n",
    "    )\n",
    ")\n",
    "print(iris1_mod.foldByKey(0, add).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e6f2c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876.4999999999998\n",
      "876.4999999999998\n"
     ]
    }
   ],
   "source": [
    "# Reduce --> used to reduce elements of a RDD (usually used for aggregation)\n",
    "from operator import add\n",
    "iris1_mod=iris1_split.map(lambda var1:float(var1[0]))\n",
    "\n",
    "print(iris1_mod.fold(0,add))\n",
    "print(iris1_mod.reduce(add)) # sum of values of 'Sepal_length' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80eaf522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sepal.Width', 458.6000000000001), ('Petal.Width', 179.89999999999998), ('Sepal.Length', 876.4999999999998), ('Petal.Length', 563.7000000000002)]\n"
     ]
    }
   ],
   "source": [
    "# reduce By key (similar to reduce function, except the function passed as an argument\n",
    "# to reduceByKey Function)\n",
    "\n",
    "iris1_mod = iris1_split.flatMap(\n",
    "    lambda var1: (\n",
    "        (\"Sepal.Length\", float(var1[0])),\n",
    "        (\"Sepal.Width\", float(var1[1])),\n",
    "        (\"Petal.Length\", float(var1[2])),\n",
    "        (\"Petal.Width\", float(var1[3])),\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "print(iris1_mod.reduceByKey(add).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63a542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sepal.Width', [3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.6, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3, 3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8, 3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0]), ('Petal.Width', [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2, 1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1.0, 1.3, 1.4, 1.0, 1.5, 1.0, 1.4, 1.3, 1.4, 1.5, 1.0, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.0, 1.1, 1.0, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1.0, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3, 2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2.0, 1.9, 2.1, 2.0, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2.0, 2.0, 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2.0, 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2.0, 2.3, 1.8])]\n"
     ]
    }
   ],
   "source": [
    "# group by key\n",
    "iris1_mod = iris1_split.flatMap(\n",
    "    lambda var1: (\n",
    "        (\"Sepal.Length\", float(var1[0])),\n",
    "        (\"Sepal.Width\", float(var1[1])),\n",
    "        (\"Petal.Length\", float(var1[2])),\n",
    "        (\"Petal.Width\", float(var1[3])),\n",
    "    )\n",
    ")\n",
    "\n",
    "# print(iris1_mod.groupByKey().collect()) # prints in iterable objects\n",
    "# to conver this to list or any other object form we use mapValues \n",
    "group1=iris1_mod.groupByKey()\n",
    "print(group1.mapValues(list).take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d5e8f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sepal.Width', 458.60000000000014), ('Petal.Width', 179.90000000000012), ('Sepal.Length', 876.5000000000002), ('Petal.Length', 563.7000000000004)]\n"
     ]
    }
   ],
   "source": [
    "# groupByKey & mapValues\n",
    "iris1_mod = iris1_split.flatMap(\n",
    "    lambda var1: (\n",
    "        (\"Sepal.Length\", float(var1[0])),\n",
    "        (\"Sepal.Width\", float(var1[1])),\n",
    "        (\"Petal.Length\", float(var1[2])),\n",
    "        (\"Petal.Width\", float(var1[3])),\n",
    "    )\n",
    ")\n",
    "print(iris1_mod.groupByKey().mapValues(sum).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8c06b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3\n",
      "7.9\n",
      "5.843333333333332\n"
     ]
    }
   ],
   "source": [
    "# Calculating Minimum, Maximum and Mean of data\n",
    "iris1_mod=iris1_split.map(lambda var1:float(var1[0]))\n",
    "\n",
    "print(iris1_mod.min())\n",
    "print(iris1_mod.max())\n",
    "print(iris1_mod.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ea44ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8253012917851412\n",
      "0.6811222222222227\n"
     ]
    }
   ],
   "source": [
    "# measuring standard deviation & variance\n",
    "print(iris1_mod.stdev())\n",
    "print(iris1_mod.variance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bcd1380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count: 150, mean: 5.843333333333332, stdev: 0.8253012917851412, max: 7.9, min: 4.3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical Summary of an RDD\n",
    "iris1_mod.stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
